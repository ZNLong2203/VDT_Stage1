# Real-Time Data Pipeline: PostgreSQL CDC â†’ Flink â†’ StarRocks â†’ Metabase

Dá»± Ã¡n nÃ y minh há»a má»™t data pipeline real-time hoÃ n chá»‰nh sá»­ dá»¥ng:
- **PostgreSQL** lÃ m CDC source vá»›i sample e-commerce data
- **Apache Flink 1.18** vá»›i CDC connectors cho real-time streaming (local installation)
- **StarRocks** all-in-one lÃ m OLAP analytical database
- **Metabase** cho business intelligence vÃ  dashboarding

## Architecture Overview

```
PostgreSQL (CDC Source) â†’ Flink CDC (Local) â†’ StarRocks (All-in-One) â†’ Metabase (BI)
```

## ğŸš€ Quick Start (Láº§n Ä‘áº§u má»Ÿ project)

### Prerequisites
- **Docker vÃ  Docker Compose** - Ä‘á»ƒ cháº¡y cÃ¡c services containerized
- **Java 8+** - Ä‘á»ƒ cháº¡y Flink local
- **MySQL client** - Ä‘á»ƒ káº¿t ná»‘i StarRocks
- **Ãt nháº¥t 8GB RAM** Ä‘á»ƒ cháº¡y táº¥t cáº£ services

### 1. First Time Setup (Cháº¡y má»™t láº§n duy nháº¥t)

```bash
# Clone project
git clone <repository>
cd VDT_Stage1

# Khá»Ÿi Ä‘á»™ng toÃ n bá»™ pipeline (first time)
./start-pipeline.sh
```

Script nÃ y sáº½ tá»± Ä‘á»™ng:
- âœ… Kiá»ƒm tra prerequisites (Docker, Java, MySQL client)
- âœ… Start táº¥t cáº£ Docker containers (PostgreSQL, StarRocks, Metabase)
- âœ… Download vÃ  setup Flink CDC local
- âœ… Táº¡o replication slots trong PostgreSQL
- âœ… Setup StarRocks schema
- âœ… Start Flink cluster
- âœ… Submit CDC jobs
- âœ… Cháº¡y test pipeline tá»± Ä‘á»™ng

### 2. Subsequent Starts (Nhá»¯ng láº§n sau)

```bash
# Quick start cho nhá»¯ng láº§n má»Ÿ project tiáº¿p theo
./quick-start.sh
```

## ğŸ§ª Testing Pipeline

### Test Real-time CDC
```bash
# Test luá»“ng CDC real-time
./scripts/test-pipeline.sh
```

Test nÃ y sáº½:
- Insert dá»¯ liá»‡u má»›i vÃ o PostgreSQL
- Kiá»ƒm tra dá»¯ liá»‡u cÃ³ xuáº¥t hiá»‡n trong StarRocks trong <10 giÃ¢y
- BÃ¡o cÃ¡o káº¿t quáº£ PASS/FAIL

### Kiá»ƒm tra Status
```bash
# Kiá»ƒm tra tráº¡ng thÃ¡i toÃ n bá»™ pipeline
./check-status.sh
```

### Manual Testing
```bash
# Insert test data vÃ o PostgreSQL
docker exec postgres-cdc psql -U postgres -d ecommerce -c "
INSERT INTO customers (name, email) VALUES ('Manual Test', 'manual@test.com');
"

# Kiá»ƒm tra trong StarRocks (sau ~5 giÃ¢y)
mysql -h localhost -P 9030 -u root --protocol=TCP -e "
USE ecommerce_dw; 
SELECT * FROM customers WHERE email = 'manual@test.com';
"
```

## ğŸ“Š Services vÃ  Ports

| Service | Port | Description | URL |
|---------|------|-------------|-----|
| PostgreSQL | 5432 | Source database vá»›i CDC enabled | `postgresql://localhost:5432/ecommerce` |
| Flink Web UI | 8081 | Flink cluster management | http://localhost:8081 |
| StarRocks FE | 8030 | StarRocks Frontend (HTTP) | http://localhost:8030 |
| StarRocks MySQL | 9030 | StarRocks MySQL protocol | `mysql://localhost:9030` |
| Metabase | 3000 | BI Dashboard | http://localhost:3000 |

## ğŸ”§ Management Commands

```bash
# Start pipeline
./start-pipeline.sh          # Láº§n Ä‘áº§u tiÃªn
./quick-start.sh            # Nhá»¯ng láº§n sau

# Test pipeline
./scripts/test-pipeline.sh   # Test real-time CDC

# Check status
./check-status.sh           # Kiá»ƒm tra tráº¡ng thÃ¡i táº¥t cáº£ services

# Stop pipeline
./stop-pipeline.sh          # Dá»«ng toÃ n bá»™ pipeline

# Manual operations
docker compose ps           # Xem containers
docker compose logs postgres # Xem logs PostgreSQL
```

## ğŸ“ˆ Metabase Setup

1. Má»Ÿ http://localhost:3000
2. Complete initial setup
3. Add StarRocks database:
   - **Type**: MySQL
   - **Host**: localhost
   - **Port**: 9030
   - **Database**: ecommerce_dw
   - **Username**: root
   - **Password**: (Ä‘á»ƒ trá»‘ng)

4. Sá»­ dá»¥ng cÃ¡c analytical views cÃ³ sáºµn:
   - `customer_summary` - TÃ³m táº¯t khÃ¡ch hÃ ng
   - `product_performance` - Performance sáº£n pháº©m
   - `daily_sales` - Doanh sá»‘ hÃ ng ngÃ y
   - `order_details` - Chi tiáº¿t Ä‘Æ¡n hÃ ng

## ğŸ—‚ï¸ Sample Data Schema

Pipeline bao gá»“m sample e-commerce schema:
- `customers` - ThÃ´ng tin khÃ¡ch hÃ ng
- `orders` - Giao dá»‹ch Ä‘Æ¡n hÃ ng
- `order_items` - Chi tiáº¿t sáº£n pháº©m trong Ä‘Æ¡n hÃ ng
- `products` - Catalog sáº£n pháº©m

## ğŸ“‹ Real-Time Testing Workflow

1. **Kiá»ƒm tra pipeline status**:
   ```bash
   ./check-status.sh
   ```

2. **Cháº¡y automated test**:
   ```bash
   ./scripts/test-pipeline.sh
   ```

3. **Test manual real-time**:
   ```bash
   # Insert trong PostgreSQL
   docker exec postgres-cdc psql -U postgres -d ecommerce -c "
   INSERT INTO customers (name, email) VALUES ('Test User', 'test@example.com');
   "
   
   # Kiá»ƒm tra StarRocks sau 5 giÃ¢y
   mysql -h localhost -P 9030 -u root --protocol=TCP -e "
   USE ecommerce_dw; SELECT * FROM customers WHERE email = 'test@example.com';
   "
   ```

## ğŸ› ï¸ Troubleshooting

### Flink khÃ´ng start Ä‘Æ°á»£c
```bash
# Kiá»ƒm tra Java version
java -version

# Restart Flink
cd flink-local/flink-1.18.0
./bin/stop-cluster.sh
./bin/start-cluster.sh
```

### StarRocks connection failed
```bash
# Kiá»ƒm tra container
docker ps | grep starrocks

# Kiá»ƒm tra MySQL connection
mysql -h localhost -P 9030 -u root --protocol=TCP -e "SELECT 1;"
```

### CDC jobs khÃ´ng cháº¡y
```bash
# Kiá»ƒm tra replication slots
docker exec postgres-cdc psql -U postgres -d ecommerce -c "
SELECT slot_name, active FROM pg_replication_slots;
"

# Submit láº¡i CDC jobs
./scripts/run-flink-cdc-job.sh
```

## âš¡ Performance Characteristics

- **Latency**: End-to-end < 5 seconds
- **Throughput**: Thousands of transactions per second
- **Reliability**: Exactly-once processing semantics
- **Scalability**: Horizontal scaling via Flink parallelism

## ğŸ§¹ Cleanup

```bash
# Stop toÃ n bá»™ pipeline
./stop-pipeline.sh

# XÃ³a táº¥t cáº£ data
docker compose down -v

# XÃ³a Flink installation (optional)
rm -rf flink-local/
```

## ğŸ“š Architecture Details

Chi tiáº¿t technical documentation xem trong `docs/architecture.md`.

## ğŸ¯ Expected Results

Sau khi cháº¡y `./scripts/test-pipeline.sh`, báº¡n sáº½ tháº¥y:

```
ğŸ§ª Testing Real-Time Data Pipeline...
ğŸ“ Inserting new customer into PostgreSQL...
ğŸ“ Inserting new product into PostgreSQL...
ğŸ“ Inserting new order into PostgreSQL...
ğŸ“ Inserting order items into PostgreSQL...
â³ Waiting for CDC to propagate changes (10 seconds)...
ğŸ” Checking data in StarRocks...
âœ… Pipeline test PASSED! All data successfully replicated to StarRocks.
```

Pipeline Ä‘Ã£ sáºµn sÃ ng cho production vá»›i real-time data streaming! ğŸš€ 