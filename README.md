# Real-Time Data Pipeline: PostgreSQL CDC â†’ Flink â†’ StarRocks â†’ Metabase

Dá»± Ã¡n nÃ y minh há»a má»™t data pipeline real-time hoÃ n chá»‰nh sá»­ dá»¥ng **Olist Brazilian E-Commerce Dataset** tháº­t:
- **PostgreSQL** lÃ m CDC source vá»›i Olist e-commerce data (7 báº£ng nguá»“n, CDC 5 báº£ng chá»n lá»c)
- **Apache Flink 1.18** vá»›i CDC connectors cho real-time streaming (local installation)
- **StarRocks** all-in-one lÃ m OLAP analytical database
- **Metabase** cho business intelligence vÃ  dashboarding

## Architecture Overview

```
PostgreSQL (Olist Dataset) â†’ Flink CDC (5 Selected Tables) â†’ StarRocks ODS â†’ Metabase (BI)
```

## ğŸ“Š Olist Dataset Schema

Pipeline sá»­ dá»¥ng **Olist Brazilian E-Commerce Dataset** vá»›i **CDC 5 báº£ng chÃ­nh**:

### PostgreSQL Source (7 tables total):
- **`customers`** - ThÃ´ng tin khÃ¡ch hÃ ng (customer_id, city, state, zip_code)
- **`sellers`** - ThÃ´ng tin ngÆ°á»i bÃ¡n (seller_id, city, state, zip_code)  
- **`products`** - Catalog sáº£n pháº©m (product_id, category, dimensions, weight)
- **`orders`** - ÄÆ¡n hÃ ng (order_id, status, timestamps, customer_id)
- **`order_items`** - Chi tiáº¿t sáº£n pháº©m trong Ä‘Æ¡n (order_id, product_id, seller_id, price)
- **`payments`** - Thanh toÃ¡n (order_id, payment_type, value, installments)
- **`reviews`** - ÄÃ¡nh giÃ¡ (review_id, order_id, score, comments)

### StarRocks ODS (5 selected tables with filtered columns):
- **`ods_orders`** - Order facts (order_id, customer_id, status, timestamps)
- **`ods_order_items`** - Order item facts (order_id, product_id, price, freight_value)
- **`ods_products`** - Product dimension (product_id, category_name)
- **`ods_payments`** - Payment facts (order_id, payment_type, payment_value)
- **`ods_reviews`** - Review facts (order_id, review_score)

## ğŸš€ Quick Start (Láº§n Ä‘áº§u má»Ÿ project)

### Prerequisites
- **Docker vÃ  Docker Compose** - Ä‘á»ƒ cháº¡y cÃ¡c services containerized
- **Java 8+** - Ä‘á»ƒ cháº¡y Flink local
- **MySQL client** - Ä‘á»ƒ káº¿t ná»‘i StarRocks
- **Ãt nháº¥t 8GB RAM** Ä‘á»ƒ cháº¡y táº¥t cáº£ services
- **Dataset CSV files** - Ä‘áº·t trong folder `dataset/`

### 1. First Time Setup (Cháº¡y má»™t láº§n duy nháº¥t)

```bash
# Clone project
git clone <repository>
cd VDT_Stage1

# Äáº£m báº£o cÃ³ dataset CSV files trong folder dataset/
ls dataset/
# Cáº§n cÃ³: olist_customers_dataset.csv, olist_sellers_dataset.csv, 
#         olist_products_dataset.csv, olist_orders_dataset.csv,
#         olist_order_items_dataset.csv, olist_order_payments_dataset.csv,
#         olist_order_reviews_dataset.csv

# Khá»Ÿi Ä‘á»™ng toÃ n bá»™ pipeline (first time)
./start-pipeline.sh
```

Script nÃ y sáº½ tá»± Ä‘á»™ng:
- âœ… Kiá»ƒm tra prerequisites (Docker, Java, MySQL client)
- âœ… Start táº¥t cáº£ Docker containers (PostgreSQL, StarRocks, Metabase)
- âœ… Download vÃ  setup Flink CDC local
- âœ… Load toÃ n bá»™ Olist dataset vÃ o PostgreSQL (7 báº£ng)
- âœ… Táº¡o replication slots cho 5 báº£ng Ä‘Æ°á»£c chá»n
- âœ… Setup StarRocks ODS schema (5 báº£ng)
- âœ… Start Flink cluster
- âœ… Submit 5 CDC jobs
- âœ… Cháº¡y test pipeline tá»± Ä‘á»™ng

### 2. Subsequent Starts (Nhá»¯ng láº§n sau)

```bash
# Quick start cho nhá»¯ng láº§n má»Ÿ project tiáº¿p theo
./quick-start.sh
```

## ğŸ§ª Testing Pipeline

### Test Real-time CDC
```bash
# Test luá»“ng CDC real-time vá»›i 5 báº£ng Ä‘Æ°á»£c chá»n
./scripts/test-pipeline.sh
```

Test nÃ y sáº½:
- Insert test records vÃ o 5 báº£ng PostgreSQL
- Kiá»ƒm tra dá»¯ liá»‡u cÃ³ xuáº¥t hiá»‡n trong StarRocks ODS trong <15 giÃ¢y
- BÃ¡o cÃ¡o káº¿t quáº£ PASS/FAIL cho 5 báº£ng Ä‘Æ°á»£c CDC

### Kiá»ƒm tra Status
```bash
# Kiá»ƒm tra tráº¡ng thÃ¡i toÃ n bá»™ pipeline
./check-status.sh
```

### Manual Testing
```bash
# Insert test data vÃ o PostgreSQL
docker exec postgres-cdc psql -U postgres -d ecommerce -c "
INSERT INTO orders (order_id, customer_id, order_status, order_purchase_timestamp) 
VALUES ('manual_test_001', (SELECT customer_id FROM customers LIMIT 1), 'processing', NOW());
"

# Kiá»ƒm tra trong StarRocks (sau ~5 giÃ¢y)
mysql -h localhost -P 9030 -u root --protocol=TCP -e "
USE ecommerce_dw; 
SELECT * FROM ods_orders WHERE order_id = 'manual_test_001';
"
```

## ğŸ“Š Services vÃ  Ports

| Service | Port | Description | URL |
|---------|------|-------------|-----|
| PostgreSQL | 5432 | Source database vá»›i Olist dataset (7 báº£ng) | `postgresql://localhost:5432/ecommerce` |
| Flink Web UI | 8081 | Flink cluster management (5 CDC jobs) | http://localhost:8081 |
| StarRocks FE | 8030 | StarRocks Frontend (HTTP) | http://localhost:8030 |
| StarRocks MySQL | 9030 | StarRocks MySQL protocol | `mysql://localhost:9030` |
| Metabase | 3000 | BI Dashboard | http://localhost:3000 |

## ğŸ”§ Management Commands

```bash
# Start pipeline
./start-pipeline.sh          # Láº§n Ä‘áº§u tiÃªn (load dataset)
./quick-start.sh            # Nhá»¯ng láº§n sau

# Test pipeline
./scripts/test-pipeline.sh   # Test real-time CDC cho 5 báº£ng Ä‘Æ°á»£c chá»n

# Check status
./check-status.sh           # Kiá»ƒm tra tráº¡ng thÃ¡i táº¥t cáº£ services

# Stop pipeline
./stop-pipeline.sh          # Dá»«ng toÃ n bá»™ pipeline

# Manual operations
docker compose ps           # Xem containers
docker compose logs postgres # Xem logs PostgreSQL
```

## ğŸ“ˆ Metabase Setup

1. Má»Ÿ http://localhost:3000
2. Complete initial setup
3. Add StarRocks database:
   - **Type**: MySQL
   - **Host**: localhost
   - **Port**: 9030
   - **Database**: ecommerce_dw
   - **Username**: root
   - **Password**: (Ä‘á»ƒ trá»‘ng)

4. Sá»­ dá»¥ng cÃ¡c analytical views cÃ³ sáºµn:
   - `daily_order_summary` - TÃ³m táº¯t Ä‘Æ¡n hÃ ng theo ngÃ y
   - `payment_by_type` - PhÃ¢n tÃ­ch thanh toÃ¡n theo loáº¡i
   - `review_by_status` - Review theo tráº¡ng thÃ¡i Ä‘Æ¡n hÃ ng

## ğŸ—‚ï¸ Real Dataset Information

**Olist Brazilian E-Commerce Dataset** bao gá»“m:
- **~100K orders** tá»« 2016-2018
- **~100K customers** trÃªn toÃ n Brazil
- **~3K sellers** 
- **~33K products** vá»›i 74 categories
- **~100K payments** vá»›i nhiá»u phÆ°Æ¡ng thá»©c
- **~100K reviews** vá»›i scores 1-5

**CDC chá»‰ stream 5 báº£ng quan trá»ng** Ä‘á»ƒ tá»‘i Æ°u hÃ³a performance vÃ  táº­p trung vÃ o analytical workload.

## ğŸ“‹ Real-Time Testing Workflow

1. **Kiá»ƒm tra pipeline status**:
   ```bash
   ./check-status.sh
   ```

2. **Cháº¡y automated test**:
   ```bash
   ./scripts/test-pipeline.sh
   ```

3. **Test manual real-time**:
   ```bash
   # Insert trong PostgreSQL
   docker exec postgres-cdc psql -U postgres -d ecommerce -c "
   INSERT INTO orders (order_id, customer_id, order_status, order_purchase_timestamp) 
   VALUES ('manual_order_001', (SELECT customer_id FROM customers LIMIT 1), 'processing', NOW());
   "
   
   # Kiá»ƒm tra StarRocks sau 5 giÃ¢y
   mysql -h localhost -P 9030 -u root --protocol=TCP -e "
   USE ecommerce_dw; SELECT * FROM ods_orders WHERE order_id = 'manual_order_001';
   "
   ```

## ğŸ› ï¸ Troubleshooting

### Flink khÃ´ng start Ä‘Æ°á»£c
```bash
# Kiá»ƒm tra Java version
java -version

# Restart Flink
cd flink-local/flink-1.18.0
./bin/stop-cluster.sh
./bin/start-cluster.sh
```

### StarRocks connection failed
```bash
# Kiá»ƒm tra container
docker ps | grep starrocks

# Kiá»ƒm tra MySQL connection
mysql -h localhost -P 9030 -u root --protocol=TCP -e "SELECT 1;"
```

### CDC jobs khÃ´ng cháº¡y
```bash
# Kiá»ƒm tra replication slots (should see 5 slots)
docker exec postgres-cdc psql -U postgres -d ecommerce -c "
SELECT slot_name, active FROM pg_replication_slots;
"

# Submit láº¡i CDC jobs
./scripts/run-flink-cdc-job.sh
```

### Dataset loading issues
```bash
# Kiá»ƒm tra CSV files
ls -la dataset/

# Kiá»ƒm tra PostgreSQL logs
docker logs postgres-cdc

# Manual data check
docker exec postgres-cdc psql -U postgres -d ecommerce -c "
SELECT 'customers', COUNT(*) FROM customers UNION
SELECT 'orders', COUNT(*) FROM orders;
"
```

## âš¡ Performance Characteristics

- **Latency**: End-to-end < 5 seconds cho real-time updates
- **Throughput**: Thousands of transactions per second  
- **Data Volume**: ~600K+ records tá»« Olist dataset (PostgreSQL), CDC chá»‰ 5 báº£ng quan trá»ng
- **Reliability**: Exactly-once processing semantics
- **Scalability**: Horizontal scaling via Flink parallelism

## ğŸ§¹ Cleanup

```bash
# Stop toÃ n bá»™ pipeline
./stop-pipeline.sh

# XÃ³a táº¥t cáº£ data
docker compose down -v

# XÃ³a Flink installation (optional)
rm -rf flink-local/
```

## ğŸ“š Architecture Details

Chi tiáº¿t technical documentation xem trong `docs/architecture.md`.

## ğŸ¯ Expected Results

Sau khi cháº¡y `./scripts/test-pipeline.sh`, báº¡n sáº½ tháº¥y:

```
ğŸ§ª Testing Real-Time Data Pipeline for 5 Selected Tables...
ğŸ“ Inserting new product into PostgreSQL...
ğŸ“ Inserting new order into PostgreSQL...
ğŸ“ Inserting order item into PostgreSQL...
ğŸ“ Inserting payment into PostgreSQL...
ğŸ“ Inserting review into PostgreSQL...
â³ Waiting for CDC to propagate changes (15 seconds)...
ğŸ” Checking data in StarRocks ODS tables...
âœ… Pipeline test PASSED! All 5 selected tables successfully replicated to StarRocks.
```

Pipeline Ä‘Ã£ sáºµn sÃ ng vá»›i **5 báº£ng Ä‘Æ°á»£c chá»n lá»c** tá»« Olist e-commerce data vÃ  real-time streaming tá»‘i Æ°u! ğŸš€ 